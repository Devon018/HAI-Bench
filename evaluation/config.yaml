# Model API configurations
api:
  openrouter:
    api_key: "${OPENROUTER_API_KEY}"
    base_url: "https://openrouter.ai/api/v1"
    temperature: 0.7
    top_p: 0.9
    max_tokens: 4096
    presence_penalty: 0.0
    frequency_penalty: 0.0
    timeout: 120


# VLLM offline inference configurations
vllm:
  path: "../models/"
  inference:
    temperature: 0.7
    top_p: 0.9
    top_k: 50
    max_tokens: 4096
    presence_penalty: 0.0
    frequency_penalty: 0.0
    num_beams: 1
    repetition_penalty: 1.0
    use_beam_search: false
    batch_size: 4
    gpu_memory_utilization: 0.9
    dtype: "auto"
    tensor_parallel_size: 4
    limit_mmm_per_prompt: 20

# Evaluation settings
evaluation:
  seed: 42